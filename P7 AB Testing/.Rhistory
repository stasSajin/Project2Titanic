library(devtools)
devtools::install_github("wesm/feather/R")
devtools::install_github("wesm/feather/R")
library(eyetrackerR)
library(eyetrackerR)
library("eyetrackingR", lib.loc="C:/Program Files/R/R-3.2.3/library")
analyze_time_clusters()
UseMethod("analyze_time_clusters")
methods(analyze_time_clusters)
methods(analyze_time_clusters.time_cluster_data)
?methods
methods(analyze_time_clusters)
getAnywhere('analyze_time_clusters')
getAnywhere('analyze_time_clusters')
getAnywhere('analyze_time_clusters.default')
getMethod(analyze_time_clusters)
methods(analyze_time_clusters)
>methods
?methods
methods(analyze_time_clusters)
getAnywhere(analyze_time_clusters.time_cluster_data)
edit(getAnywhere(analyze_time_clusters.time_cluster_data))
?analyze_time_clusters
p=300/2000
z=2.57
se=sqrt(p*(1-p)/2000)
z*se
p+z*se
p-z*se
974/10072
1242/9886
.1256322-.09670373
p=.111
z=1.96
se=.00445
0.02892847+z*se
0.02892847-z*se
z*se
data=c(87029, 113407, 84843, 104994, 99327, 92052, 60684)
mean(data)
sd(data)
se=sd(data)/sqrt(7)
mean(data)+z*se
mean(data)-z*se
pPool=(2500+2500)/(100000)
pPool=(2500+2500+302+374)/(100000+6021+5979)
sqrt(pPool*(1-pPool)*(1/(50000+6021)+1/(50000+5979)))
get_z_star = function(alpha) {
return(-qnorm(alpha / 2))
}
get_beta = function(z_star, s, d_min, N) {
SE = s /  sqrt(N)
return(pnorm(z_star * SE, mean=d_min, sd=SE))
}
required_size = function(s, d_min, Ns=1:20000, alpha=0.05, beta=0.2) {
for (N in Ns) {
if (get_beta(get_z_star(alpha), s, d_min, N) <= beta) {
return(N)
}
}
required_size = function(s, d_min, Ns=1:20000, alpha=0.05, beta=0.2) {
for (N in Ns) {
if (get_beta(get_z_star(alpha), s, d_min, N) <= beta) {
return(N)
}
}
return(-1)
}
required_size = function(s, d_min, Ns=1:20000, alpha=0.05, beta=0.2) {
for (N in Ns) {
if (get_beta(get_z_star(alpha), s, d_min, N) <= beta) {
return(N)
}
}
return(-1)
}
required_size(s=sqrt(0.1*0.9*2), d_min=0.02)
required_size(s=sqrt(0.1*0.9*2), d_min=0.02)
j
h
h
get_z_star = function(alpha) {
return(-qnorm(alpha / 2))
}
get_beta = function(z_star, s, d_min, N) {
SE = s /  sqrt(N)
return(pnorm(z_star * SE, mean=d_min, sd=SE))
}
required_size = function(s, d_min, Ns=1:20000, alpha=0.05, beta=0.2) {
for (N in Ns) {
if (get_beta(get_z_star(alpha), s, d_min, N) <= beta) {
return(N)
}
}
return(-1)
}
required_size(s=sqrt(0.1*0.9*2), d_min=0.02)
required_size(s=0.00515*sqrt(5000), d_min=0.02)
required_size(s=0.0119*sqrt(5000), d_min=0.02)
15312/(15348+15312)
.5+1.96*sqrt((.5*.5)/(15348+15312))
.5-1.96*sqrt((.5*.5)/(15348+15312))
15348/(15348+15312)
Xs_cont <- c(196, 200, 200, 216, 212, 185, 225, 187, 205, 211, 192, 196, 223, 192)
Ns_cont <- c(2029, 1991, 1951, 1985, 1973, 2021, 2041, 1980, 1951, 1988, 1977, 2019, 2035, 2007)
Xs_exp <- c(179, 208, 205, 175, 191, 291, 278, 216, 225, 207, 205, 200, 297, 299)
Ns_exp <- c(1971, 2009, 2049, 2015, 2027, 1979, 1959, 2020, 2049, 2012, 2023, 1981, 1965, 1993)
controlCTR<-Xs_cont/Ns_cont
expCTR<-Xs_exp/Ns_exp
controlCTR
expSum<-sum(Ns_exp)
contSum<-sum(Ns_cont)
contSum
(.0035*sqrt(1/(expSum)+1/(expCTR)))/sqrt(2/10000)
expSum
(.0035*sqrt(1/(expSum)+1/(contSum)))/sqrt(2/10000)
se<-(.0035*sqrt(1/(expSum)+1/(contSum)))/sqrt(2/10000)
se<-(.0062*sqrt(1/(expSum)+1/(contSum)))/sqrt(2/5000)
se
1.96*se
-1.96*se
sum(Xs_exp)/sum(Ns_cont)-sum(Xs_cont)/sum(Ns_cont)
d_hat<-sum(Xs_exp)/sum(Ns_cont)-sum(Xs_cont)/sum(Ns_cont)
d_hat+1.96*se
d_hat-1.96*se
sum(expCTR>controlCTR)
expSum
contSum
sum(Xs_exp)/sum(Ns_cont)
sum(Xs_cont)/sum(Ns_cont)
d_hat
expSum
se
expCTR<-Xs_exp/Ns_exp
expCTR
d_hat<-sum(Xs_exp)/sum(Ns_exp)-sum(Xs_cont)/sum(Ns_cont)
d_hat+1.96*se
d_hat-1.96*se
d_hat
1-.95^3
1-.95^10
1-.99^10
.03/.013
.5/.21
install.packages("ggnetwork")
library(ggplot2)
library(dplyr)
library(rvest)
library(network)
library(sna)
library(ggnetwork)
library(wesanderson)
install.packages("wesanderson")
library(wesanderson)
library(rvest)
z = "icelandic-legal-code.zip"
u = "http://www.althingi.is/lagasafn/zip/nuna/allt.zip"
if (!file.exists(z))
download.file(u, z, mode = "wb")
baseline<-read.csv("baselineInfo.csv")
setwd("C:/everything/Classes/UdacityNanodegrees/DataAnalyst/UdacityDataAnalystNanodegree/P7 AB Testing")
baseline<-read.csv("baselineInfo.csv")
data<-read.csv("data.csv")
control<-subset(data, Group=="Control")
experimental<-subset(data, Group=="Experimental")
dataComplete<-na.omit(data)
dataComplete$GrossConversion<-dataComplete$Enrollments/dataComplete$Clicks
dataComplete$NetRetention<-dataComplete$Payments/dataComplete$Clicks
dataControl<-subset(dataComplete, Group=="Control")
dataExperimental<-subset(dataComplete, Group=="Experimental")
install.packages("equivalence")
library(equivalence)
tost(dataControl$NetRetention, dataExperimental$NetRetention)
equivalence.xyplot(dataControl$NetRetention ~ dataExperimental$NetRetention,
alpha=0.05, b0.ii=0.1, b1.ii=0.2,
xlab="Predicted height (m)",
ylab="Measured height (m)")
ptte.data((dataExperimental$NetRetention-dataControl$NetRetention), alpha = 0.05, Epsilon = 0.25)
ptte.stat(mean(dataExperimental$NetRetention - dataControl$NetRetention, na.rm=TRUE),
sd(dataExperimental$NetRetention - dataControl$NetRetention, na.rm=TRUE),
n=685325)
ptte.stat(mean(dataExperimental$NetRetention - dataControl$NetRetention, na.rm=TRUE),
sd(dataExperimental$NetRetention - dataControl$NetRetention, na.rm=TRUE),
n=685325)
